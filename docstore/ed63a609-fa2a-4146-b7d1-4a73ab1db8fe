2.2 Convolutional layer

As the name implies, the convolutional layer plays a vital role in how CNNs operate. The layers parameters focus around the use of learnable kernels.

6 Keiron O’Shea et al.

These kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each ﬁlter across the spatial dimensionality of the input to produce a 2D activation map. These activation maps can be visualised, as seen in Figure 3.

As we glide through the input, the scalar product is calculated for each value in that kernel. (Figure 4) From this the network will learn kernels that ’ﬁre’ when they see a speciﬁc feature at a given spatial position of the input. These are commonly known as activations.

Input Vector O;o;o}o}oyo Pooled Vector Kernel Destination Pixel ofif2}ifafa ofo}o 4}o}o ofafafafasa e}o}i]2 e}o]o]}o >| 8 1}ofo}ofojo ofafa o}o]-4 ofofififafo ofafalafaya

Fig.4: A visual representation of a convolutional layer. The centre element of the kernel is placed over the input vector, of which is then calculated and replaced with a weighted sum of itself and any nearby pixels.

Every kernel will have a corresponding activation map, of which will be stacked along the depth dimension to form the full output volume from the convolu- tional layer.

As we alluded to earlier, training ANNs on inputs such as images results in models of which are too big to train effectively. This comes down to the fully- connected manner of standard ANN neurons, so to mitigate against this every neuron in a convolutional layer is only connected to small region of the input volume. The dimensionality of this region is commonly referred to as the re- ceptive ﬁeld size of the neuron. The magnitude of the connectivity through the depth is nearly always equal to the depth of the input.

For example, if the input to the network is an image of size 64 × 64 × 3 (a RGB- coloured image with a dimensionality of 64 × 64) and we set the receptive ﬁeld size as 6 × 6, we would have a total of 108 weights on each neuron within the convolutional layer. (6 × 6 × 3 where 3 is the magnitude of connectivity across the depth of the volume) To put this into perspective, a standard neuron seen in other forms of ANN would contain 12,288 weights each.

Convolutional layers are also able to signiﬁcantly reduce the complexity of the model through the optimisation of its output. These are optimised through three hyperparameters, the depth, the stride and setting zero-padding.

Introduction to Convolutional Neural Networks 7

The depth of the output volume produced by the convolutional layers can be manually set through the number of neurons within the layer to a the same region of the input. This can be seen with other forms of ANNs, where the all of the neurons in the hidden layer are directly connected to every single neuron beforehand. Reducing this hyperparameter can signiﬁcantly minimise the total number of neurons of the network, but it can also signiﬁcantly reduce the pattern recognition capabilities of the model.

We are also able to deﬁne the stride in which we set the depth around the spatial dimensionality of the input in order to place the receptive ﬁeld. For example if we were to set a stride as 1, then we would have a heavily overlapped receptive ﬁeld producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.

Zero-padding is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes.

It is important to understand that through using these techniques, we will alter the spatial dimensionality of the convolutional layers output. To calculate this, you can make use of the following formula:

(V − R) + 2Z S + 1

Where V represents the input volume size (height×width×depth), R represents the receptive ﬁeld size, Z is the amount of zero padding set and S referring to the stride. If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to ﬁt neatly across the given input.

Despite our best efforts so far we will still ﬁnd that our models are still enor- mous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer.

Parameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer.

As a result of this as the backpropagation stage occurs, each neuron in the out- put will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.

8 Keiron O’Shea et al.
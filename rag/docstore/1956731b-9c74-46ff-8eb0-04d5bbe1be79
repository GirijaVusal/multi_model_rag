A preliminary version of this manuscript was pub- lished previously [10]. Since then, the frameworks of RPN and Faster R-CNN have been adopted and gen- eralized to other methods, such as 3D object detection [13], part-based detection [14], instance segmentation [15], and image captioning [16]. Our fast and effective object detection system has also been built in com-

2 RELATED WORK

Object Proposals. There is a large literature on object proposal methods. Comprehensive surveys and com- parisons of object proposal methods can be found in [19], [20], [21]. Widely used object proposal methods include those based on grouping super-pixels (e.g., Selective Search [4], CPMC [22], MCG [23]) and those based on sliding windows (e.g., objectness in windows [24], EdgeBoxes [6]). Object proposal methods were adopted as external modules independent of the de- tectors (e.g., Selective Search [4] object detectors, R- CNN [5], and Fast R-CNN [2]).

Deep Networks for Object Detection. The R-CNN method [5] trains CNNs end-to-end to classify the proposal regions into object categories or background. R-CNN mainly plays as a classiﬁer, and it does not predict object bounds (except for reﬁning by bounding box regression). Its accuracy depends on the perfor- mance of the region proposal module (see compar- isons in [20]). Several papers have proposed ways of using deep networks for predicting object bounding boxes [25], [9], [26], [27]. In the OverFeat method [9], a fully-connected layer is trained to predict the box coordinates for the localization task that assumes a single object. The fully-connected layer is then turned

1. Since the publication of the conference version of this paper [10], we have also found that RPNs can be trained jointly with Fast R-CNN networks leading to less training time.

2. http://image-net.org/challenges/LSVRC/2015/results

2

classifier

Rol

pooling

proposals

Region Proposal

Network,

feature maps

conv layers

Figure 2: Faster R-CNN is a single, uniﬁed network for object detection. The RPN module serves as the ‘attention’ of this uniﬁed network.

into a convolutional layer for detecting multiple class- speciﬁc objects. The MultiBox methods [26], [27] gen- erate region proposals from a network whose last fully-connected layer simultaneously predicts mul- tiple class-agnostic boxes, generalizing the “single- box” fashion of OverFeat. These class-agnostic boxes are used as proposals for R-CNN [5]. The MultiBox proposal network is applied on a single image crop or multiple large image crops (e.g., 224×224), in contrast to our fully convolutional scheme. MultiBox does not share features between the proposal and detection networks. We discuss OverFeat and MultiBox in more depth later in context with our method. Concurrent with our work, the DeepMask method [28] is devel- oped for learning segmentation proposals.

Shared computation of convolutions [9], [1], [29], [7], [2] has been attracting increasing attention for ef- ﬁcient, yet accurate, visual recognition. The OverFeat paper [9] computes convolutional features from an image pyramid for classiﬁcation, localization, and de- tection. Adaptively-sized pooling (SPP) [1] on shared convolutional feature maps is developed for efﬁcient region-based object detection [1], [30] and semantic segmentation [29]. Fast R-CNN [2] enables end-to-end detector training on shared convolutional features and shows compelling accuracy and speed.